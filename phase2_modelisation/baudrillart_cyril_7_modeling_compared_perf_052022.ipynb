{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfeb954d",
   "metadata": {},
   "source": [
    "# Modélisation des autorisations de crédits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb915418",
   "metadata": {},
   "source": [
    "## Comparaison des perfs de différents modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce6a35b",
   "metadata": {},
   "source": [
    "L'objectif est d'avoir un premier aperçu de la performance de différents types de modèles avec des paramètres standards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3015ce",
   "metadata": {},
   "source": [
    "### Chargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd206960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies Data Science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e636b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-Learn\n",
    "from sklearn.model_selection import (cross_validate,\n",
    "                                     StratifiedKFold)\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f9f1b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalanced-Learn\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef55533f",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "429924f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données intégrales déjà retraitées et séparées en train & test sets\n",
    "# 11 features sélectionnées + undersampling + imputation des valeurs manquantes\n",
    "X_train = pd.read_csv('../data_models/X_train_imputed.csv', index_col=0)\n",
    "X_test = pd.read_csv('../data_models/X_test_imputed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9565a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation de la target\n",
    "y_train = X_train['TARGET']\n",
    "y_test = X_test['TARGET']\n",
    "# Supprimer la target des features\n",
    "X_train = X_train.drop(columns='TARGET')\n",
    "X_test = X_test.drop(columns='TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0525cac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 16792, 1.0: 16700})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comptage des classes\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42561154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 7131, 1.0: 7223})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c187b2",
   "metadata": {},
   "source": [
    "On voit que les classes ont bien été égalisées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc0db2b",
   "metadata": {},
   "source": [
    "# Tests de différents modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eabf37",
   "metadata": {},
   "source": [
    "Sélection de modèles adaptés aux données de grande taille. Pour plus de détails, voir note méthodologique. Les SVM et les KNN ne sont pas étudiés car ils ne sont pas adaptés aux datasets de grande taille."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f43406",
   "metadata": {},
   "source": [
    "Modèles sélectionnés: Naive Bayes, régression logistique, arbre de décision, XGboost et Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4de193d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement sur le train set initial complet\n",
    "X = pd.concat([X_train,X_test])\n",
    "y = pd.concat([y_train,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e40cb22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB() with balanced class weights\n",
      "-----------------\n",
      "fit_time  : 0.02\n",
      "score_time  : 0.03\n",
      "test_recall  : 0.72\n",
      "train_recall  : 0.72\n",
      "test_auc  : 0.79\n",
      "train_auc  : 0.79\n",
      "test_f1  : 0.72\n",
      "train_f1  : 0.72\n",
      "-----------------\n",
      "Ridge with balanced class weights\n",
      "-----------------\n",
      "fit_time  : 0.03\n",
      "score_time  : 0.04\n",
      "test_recall  : 0.69\n",
      "train_recall  : 0.69\n",
      "test_auc  : 0.8\n",
      "train_auc  : 0.8\n",
      "test_f1  : 0.72\n",
      "train_f1  : 0.72\n",
      "-----------------\n",
      "Decision Tree with balanced class weights\n",
      "-----------------\n",
      "fit_time  : 0.29\n",
      "score_time  : 0.02\n",
      "test_recall  : 0.72\n",
      "train_recall  : 1.0\n",
      "test_auc  : 0.69\n",
      "train_auc  : 1.0\n",
      "test_f1  : 0.7\n",
      "train_f1  : 1.0\n",
      "-----------------\n",
      "XGBoost with balanced class weights\n",
      "-----------------\n",
      "fit_time  : 1.11\n",
      "score_time  : 0.04\n",
      "test_recall  : 0.78\n",
      "train_recall  : 0.87\n",
      "test_auc  : 0.86\n",
      "train_auc  : 0.95\n",
      "test_f1  : 0.76\n",
      "train_f1  : 0.87\n",
      "-----------------\n",
      "RandomForest with balanced class weights\n",
      "-----------------\n",
      "fit_time  : 5.06\n",
      "score_time  : 0.48\n",
      "test_recall  : 0.76\n",
      "train_recall  : 1.0\n",
      "test_auc  : 0.86\n",
      "train_auc  : 1.0\n",
      "test_f1  : 0.77\n",
      "train_f1  : 1.0\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "models = [GaussianNB(),\n",
    "          RidgeClassifier(),\n",
    "          DecisionTreeClassifier(),\n",
    "          XGBClassifier(),\n",
    "          RandomForestClassifier()]\n",
    "\n",
    "names = [\"GaussianNB()\", \"Ridge\", \"Decision Tree\",\n",
    "         'XGBoost', 'RandomForest']\n",
    "\n",
    "# Calcul de la performance des modèles via une boucle unique\n",
    "for model, name in zip(models, names):\n",
    "    print (name +' with balanced class weights')\n",
    "    print(\"-----------------\")\n",
    "    start = time.time()\n",
    "    model_ = make_pipeline(StandardScaler(),\n",
    "                           model)\n",
    "    scoring = {'recall': 'recall',\n",
    "               'auc': 'roc_auc',\n",
    "               'f1': 'f1',\n",
    "               }\n",
    "    cv = StratifiedKFold(n_splits=3) \n",
    "    scores = cross_validate(model_,\n",
    "                            X, y,\n",
    "                            scoring=scoring,\n",
    "                            cv=cv,\n",
    "                            return_train_score=True)\n",
    "    for key, value in scores.items():\n",
    "        print(key, ' :', round(value.mean(), 2) )\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3686f1",
   "metadata": {},
   "source": [
    "Les modèles simples de type Naive Bayes et régression logistique donnent des performances très correctes (recall, auc_roc) avec des temps de calcul très courts. Les performances similaires à celles des méthodes plus complexes.   \n",
    "Les temps de calcul sont plus longs pour les arbres (RandomForest et XGBoost) mais ces méthodes permettent d'améliorer les perfomances. Ils ont néanmoins tendance à overfitter (performance sur le test set inférieures à celles sur le train set). XGBoost semble être un bon compris entre performance et vitesse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b97bd",
   "metadata": {},
   "source": [
    "Etudier le notebook https://colab.research.google.com/drive/1pjPzsw_uZew-Zcz646JTkRDhF2GkPk0N#scrollTo=rrTZ874kv7Hm pour aller plus loin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8178206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
